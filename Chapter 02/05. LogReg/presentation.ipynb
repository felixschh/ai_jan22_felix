{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and why we need it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is logistic Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Logistic Regression is a linear classifier\n",
    "#### - it’s often close to either 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - statistical software to understand the relationship between the dependent variable and one or more independent variables\n",
    "### - can help to predict the likelihood of an event happening or a choice being made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Independent variables must be valid. Incorrect or incomplete variables will degrade a model’s predictive value.\n",
    "### - Avoid continuous outcomes. Temperatures, time or anything that is open-ended will make the model much less precise.\n",
    "### - Do not use inter-related data. If some observations are related to one another, the model will tend to overweight their significance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - credit risk management\n",
    "### - consumer profiling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applied to a Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries and functions\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# loading the the dataset - given by sklearn\n",
    "digits = load_digits()\n",
    "# print(digits.data.shape)\n",
    "# print(digits.target.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the images to show how they look like\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:10], digits.target[0:10])):\n",
    "    plt.subplot(1, 10, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Digit: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixschekerka/opt/anaconda3/envs/strive/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting logisticRegr to Logisticregression() with default settings\n",
    "logisticRegr = LogisticRegression()\n",
    "# learning the model the relation between the digits and the labels\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict single\n",
    "logisticRegr.predict(X_test[0].reshape(1,-1))\n",
    "# predict multi\n",
    "logisticRegr.predict(X_test[0:10])\n",
    "# predict entire data-set\n",
    "predictions = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 2 6 6 7 1 9 8 5 2 8 6 6 6 6 1 0 5 8 8 7 8 4 7 5 4 9 2 9 4 7 6 8 9 4 3\n",
      " 1 0 1 8 6 7 7 1 0 7 6 2 1 9 6 7 9 0 0 9 1 6 3 0 2 3 4 1 9 2 6 9 1 8 3 5 1\n",
      " 2 8 2 2 9 7 2 3 6 0 5 3 7 5 1 2 9 9 3 1 4 7 4 8 5 8 5 5 2 5 9 0 7 1 4 7 3\n",
      " 4 8 9 7 9 8 2 1 5 2 5 8 4 1 7 0 6 1 5 5 9 9 5 9 9 5 7 5 6 2 8 6 9 6 1 5 1\n",
      " 5 9 9 1 5 3 6 1 8 9 8 7 6 7 6 5 6 0 8 8 9 9 6 1 0 4 1 6 3 8 6 7 4 9 6 3 0\n",
      " 3 3 3 0 7 7 5 7 8 0 7 1 9 6 4 5 0 1 4 6 4 3 3 0 9 5 9 2 8 4 2 1 6 8 9 2 4\n",
      " 9 3 7 6 2 3 3 1 6 9 3 6 3 3 2 0 7 6 1 1 9 7 2 7 8 5 5 7 5 3 3 7 2 7 5 5 7\n",
      " 0 9 1 6 5 9 7 4 3 8 0 3 6 4 6 3 2 6 8 8 8 4 6 7 5 2 4 5 3 2 4 6 9 4 5 4 3\n",
      " 4 6 2 9 0 1 7 2 0 9 6 0 4 2 0 7 9 8 5 7 8 2 8 4 3 7 2 6 9 9 5 1 0 8 2 8 9\n",
      " 5 6 2 2 7 2 1 5 1 6 4 5 0 9 4 1 1 7 0 8 9 0 5 4 3 8 8 6 5 3 4 4 4 8 8 7 0\n",
      " 9 6 3 5 2 3 0 8 8 3 1 3 3 0 0 4 6 0 7 7 6 2 0 4 4 2 3 7 1 9 8 6 8 5 6 2 2\n",
      " 3 1 7 7 8 0 3 3 1 1 5 5 9 1 3 7 0 0 3 0 4 5 8 9 3 4 3 1 8 9 8 3 6 3 1 6 2\n",
      " 1 7 5 5 1 9 2 8 9 7 2 1 4 9 3 2 6 2 5 9 6 5 8 2 0 7 8 0 5 8 4 1 8 6 4 3 4\n",
      " 2 0 4 5 8 3 9 1 8 3 4 5 0 8 5 6 3 0 6 9 1 5 2 2 1 9 8 4 3 3 0 7 8 8 1 1 3\n",
      " 5 5 8 4 9 7 8 4 4 9 0 1 6 9 3 6 1 7 0 6 2 9 9 3 6 1 5 1 8 9 8 4 1 7 2 8 0\n",
      " 6 2 1 0 6 1 6 5 2 8 6 2 1 4 6 8 2 2 7 5 9 1 9 5 0 2 5 5 6 8 9 5 7 0 5 2 1\n",
      " 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# check accurracy\n",
    "accuracy = logisticRegr.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression without SciKit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n",
      "[0.99999832 0.99999999 0.99999986 0.99998893 0.99999993 1.\n",
      " 1.         1.         1.         1.         0.99999996 0.99999998\n",
      " 1.         0.9999991  0.99999409 1.         0.99998893 1.\n",
      " 1.         0.99999986]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#declare the dataframe\n",
    "df = pd.DataFrame({'age': [22,25,47,52, 46,56,55,60,62,61,18,28,27,29,49,55,25,58,19,18,21,26,40,45,50,54,23], 'bought_insurance':[0,0,1,0,1,1,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0]})\n",
    "\n",
    "# declare test and train\n",
    "test = df.sample(20)\n",
    "train = df[df.isin(test)]\n",
    "train.dropna(inplace = True)\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "def square_loss(y_pred, target):\n",
    "  return np.mean(pow((y_pred - target),2))\n",
    "\n",
    "# split data  into train and test\n",
    "X_train, y_train = train.age, train['bought_insurance']\n",
    "X_test, y_test = test.age, test['bought_insurance']\n",
    "\n",
    "# training the model\n",
    "lr = 0.01\n",
    "W = np.random.uniform(0,1)\n",
    "b = 0.1\n",
    "for i in range(10000):\n",
    "  z = np.dot(X_train, W) + b\n",
    "y_pred = sigmoid(z)\n",
    "l = square_loss(y_pred, y_train)\n",
    "gradient_W = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
    "gradient_b = np.mean(y_pred-y_train)\n",
    "W = W - lr * gradient_W\n",
    "b = b - lr * gradient_b\n",
    "\n",
    "#checking accuracy\n",
    "for i in range(len(X_test)):\n",
    "    r = sigmoid(np.dot(X_test, W) + b)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3606f1f72cab31e12ded3fd4dc568aeec6faa77d43eaca4ad210e84657d2ac3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('strive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
